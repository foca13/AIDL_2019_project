{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project siamesa_v2_sbd.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwQ4Nmxgcmri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "from torch import optim\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import os.path as osp\n",
        "from PIL import Image\n",
        "import PIL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EAo5WN-79ds",
        "colab_type": "text"
      },
      "source": [
        "ACCESS TO THE DRIVE FOLDER WHERE THE DATASET HAS BEEN STORED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLucYq9Loxgb",
        "colab_type": "code",
        "outputId": "511f925d-ced1-4aea-d6f8-7f0910539f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Final project AIDL/'  #change dir to your project folder"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHn2r5ERptEg",
        "colab_type": "text"
      },
      "source": [
        "DEFINE ARGUMENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdqM3jDv9VTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Args:\n",
        "\n",
        "    frontal_images_directories = \"gdrive/My Drive/Final project AIDL/dataset-cfp/Protocol/image_list_F.txt\"\n",
        "    profile_images_directories = \"gdrive/My Drive/Final project AIDL/dataset-cfp/Protocol/image_list_P.txt\"\n",
        "    split_main_directory = \"gdrive/My Drive/Final project AIDL/dataset-cfp/Protocol/Split\"\n",
        "    split_traindata = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\"]\n",
        "    split_valdata = [\"07\", \"08\"]\n",
        "    split_testdata = [\"09\", \"10\"]\n",
        "    dataset_root = \"gdrive/My Drive/Final project AIDL\"\n",
        "    dataset= \"CFPDataset\"\n",
        "    lr = float(5e-4)\n",
        "    weight_decay = float(0.0005)\n",
        "    momentum = float(0.9)\n",
        "    batch_size = int(16)\n",
        "    workers = int(8)\n",
        "    start_epoch = int(0)\n",
        "    epochs = int(20)\n",
        "    save_every = int(2)\n",
        "    resume = \"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHNIGrMcpw6C",
        "colab_type": "text"
      },
      "source": [
        "LOAD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_gAtqmHsofp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import os.path as osp\n",
        "from pathlib import Path\n",
        "from torch.utils.data import dataset\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class CFPDataset(dataset.Dataset):\n",
        "    def __init__(self, path, args, img_transforms=None, dataset_root=\"\",\n",
        "                 split=\"train\", input_size=(224, 224)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data = []\n",
        "        self.split = split\n",
        "\n",
        "        self.load(path, args)\n",
        "\n",
        "        print(\"Dataset loaded\")\n",
        "        print(\"{0} samples in the {1} dataset\".format(len(self.data),\n",
        "                                                      self.split))\n",
        "        self.transforms = img_transforms\n",
        "        self.dataset_root = dataset_root\n",
        "        self.input_size = input_size\n",
        "\n",
        "    def load(self, path, args):\n",
        "\n",
        "        # read directories for frontal images\n",
        "        lines = open(args.frontal_images_directories).readlines()\n",
        "        idx = 0\n",
        "        directories_frontal_images = []\n",
        "        while idx < len(lines):\n",
        "            x = lines[idx].strip().split()\n",
        "            directories_frontal_images.append(x)\n",
        "            idx += 1\n",
        "\n",
        "        # read directories for profile images\n",
        "        lines = open(args.profile_images_directories).readlines()\n",
        "        idx = 0\n",
        "        directories_profile_images = []\n",
        "        while idx < len(lines):\n",
        "            x = lines[idx].strip().split()\n",
        "            directories_profile_images.append(x)\n",
        "            idx += 1\n",
        "\n",
        "        # read same and different pairs of images and save at dictionary\n",
        "        self.data = []\n",
        "        for i in path:\n",
        "            ff_diff_file = osp.join(args.split_main_directory, 'FF', i,\n",
        "                                    'diff.txt')\n",
        "            lines = open(ff_diff_file).readlines()\n",
        "            idx = 0\n",
        "            while idx < int(len(lines)/1):\n",
        "                img_pair = lines[idx].strip().split(',')\n",
        "                img1_dir = directories_frontal_images[int(img_pair[0])][1]\n",
        "                img2_dir = directories_frontal_images[int(img_pair[1])][1]\n",
        "                pair_tag = 0.0\n",
        "                d = {\n",
        "                    \"img1_path\": img1_dir,\n",
        "                    \"img2_path\": img2_dir,\n",
        "                    \"pair_tag\": pair_tag\n",
        "                }\n",
        "                self.data.append(d)\n",
        "                idx += 1\n",
        "\n",
        "            ff_same_file = osp.join(args.split_main_directory, 'FF', i,\n",
        "                                    'same.txt')\n",
        "            lines = open(ff_same_file).readlines()\n",
        "            idx = 0\n",
        "            while idx < int(len(lines)/1):\n",
        "                img_pair = lines[idx].strip().split(',')\n",
        "                img1_dir = directories_frontal_images[int(img_pair[0])][1]\n",
        "                img2_dir = directories_frontal_images[int(img_pair[1])][1]\n",
        "                pair_tag = 1.0\n",
        "                d = {\n",
        "                    \"img1_path\": img1_dir,\n",
        "                    \"img2_path\": img2_dir,\n",
        "                    \"pair_tag\": pair_tag\n",
        "                }\n",
        "                self.data.append(d)\n",
        "                idx += 1\n",
        "\n",
        "            fp_diff_file = osp.join(args.split_main_directory, 'FP', i,\n",
        "                                    'diff.txt')\n",
        "            lines = open(fp_diff_file).readlines()\n",
        "            idx = 0\n",
        "            while idx < int(len(lines)/1):\n",
        "                img_pair = lines[idx].strip().split(',')\n",
        "                img1_dir = directories_frontal_images[int(img_pair[0])][1]\n",
        "                img2_dir = directories_profile_images[int(img_pair[1])][1]\n",
        "                pair_tag = 0.0\n",
        "                d = {\n",
        "                    \"img1_path\": img1_dir,\n",
        "                    \"img2_path\": img2_dir,\n",
        "                    \"pair_tag\": pair_tag\n",
        "                }\n",
        "                self.data.append(d)\n",
        "                idx += 1\n",
        "\n",
        "            fp_same_file = osp.join(args.split_main_directory, 'FP', i,\n",
        "                                    'same.txt')\n",
        "            lines = open(fp_same_file).readlines()\n",
        "            idx = 0\n",
        "            while idx < int(len(lines)/1):\n",
        "                img_pair = lines[idx].strip().split(',')\n",
        "                img1_dir = directories_frontal_images[int(img_pair[0])][1]\n",
        "                img2_dir = directories_profile_images[int(img_pair[1])][1]\n",
        "                pair_tag = 1.0\n",
        "                d = {\n",
        "                    \"img1_path\": img1_dir,\n",
        "                    \"img2_path\": img2_dir,\n",
        "                    \"pair_tag\": pair_tag\n",
        "                }\n",
        "                self.data.append(d)\n",
        "                idx += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        d = self.data[index]\n",
        "        image1_path = osp.join(self.dataset_root, 'dataset-cfp', d[\n",
        "            'img1_path'])\n",
        "        image2_path = osp.join(self.dataset_root, 'dataset-cfp', d[\n",
        "            'img2_path'])\n",
        "        image1 = Image.open(image1_path).convert('RGB')\n",
        "        image2 = Image.open(image2_path).convert('RGB')\n",
        "        tag = d['pair_tag']\n",
        "        if self.transforms is not None:\n",
        "            # this converts from (HxWxC) to (CxHxW) as wel\n",
        "            img1 = self.transforms(image1)\n",
        "            img2 = self.transforms(image2)\n",
        "\n",
        "        return img1, img2, tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYIFlDuZpiAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils import data\n",
        "\n",
        "def get_dataloader(datapath, args, img_transforms=None, split=\"train\"):\n",
        "\n",
        "    data_loader = data.DataLoader(CFPDataset(datapath,\n",
        "                                             args,\n",
        "                                             split=split,\n",
        "                                             img_transforms=img_transforms,\n",
        "                                             dataset_root=osp.expanduser(\n",
        "                                                 args.dataset_root)),\n",
        "                                  batch_size=args.batch_size,\n",
        "                                  shuffle=True,    \n",
        "                                  num_workers=args.workers,\n",
        "                                  pin_memory=True,\n",
        "                                  drop_last=True)\n",
        "    return data_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOTmj-LtqZnX",
        "colab_type": "text"
      },
      "source": [
        "MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OboRfyRMqbP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import vgg16_bn\n",
        "\n",
        "\n",
        "class RecognitionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Siamese network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feat = vgg16_bn(pretrained=True).features\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(in_features=512*7*7*2, out_features=4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout()\n",
        "        )\n",
        "        self.fc2 = nn.Linear(in_features=4096, out_features=2)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        # the input to the vgg16 is a fixed-size 224x224 RGB image\n",
        "        # we get the vgg16 features\n",
        "        #print(img1.size(), img2.size())\n",
        "        feat_1 = self.feat(img1)\n",
        "        feat_2 = self.feat(img2)\n",
        "        #print(feat_1.size(), feat_2.size())\n",
        "        feat_1 = feat_1.view(feat_1.size(0), -1)\n",
        "        feat_2 = feat_2.view(feat_2.size(0), -1)\n",
        "        #print(feat_1.size(), feat_2.size())\n",
        "        # we concatenate the two tensors of features\n",
        "        feat = torch.cat((feat_1, feat_2), 1)\n",
        "        #print(feat.size())\n",
        "        # we run the classifier\n",
        "        feat_3 = self.fc1(feat)\n",
        "        #print(feat_3.size)\n",
        "        tag = self.fc2(feat_3)\n",
        "        #print(tag)\n",
        "        return tag\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7A5_ZZdqf8Z",
        "colab_type": "text"
      },
      "source": [
        "LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLLRaLvFqit5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class RecognitionCriterion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.classification_criterion = nn.CrossEntropyLoss()\n",
        "        self.cls_loss = None\n",
        "\n",
        "    def forward(self, *input):\n",
        "        self.cls_loss = self.classification_criterion(*input)\n",
        "        return self.cls_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c_WD2OCqnYa",
        "colab_type": "text"
      },
      "source": [
        "TRAINING AND VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c-eqydZqtKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as nnfunc\n",
        "import numpy as np\n",
        "\n",
        "def accuracy(predictions, y):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    preds = torch.topk(predictions, k=1)\n",
        "    for p, i, label in zip(preds[0], preds[1], y):\n",
        "        #print(p, i, label)\n",
        "        total += 1\n",
        "        if i == 1 and label == 1:\n",
        "            correct += 1\n",
        "        if i == 0 and label == 0:\n",
        "            correct += 1\n",
        "    return correct/total\n",
        "\n",
        "def train(model, loss_fn, optimizer, dataloader, epoch, device):\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    all_loss = []\n",
        "    all_acc = []\n",
        "        \n",
        "    for idx, (img1, img2, prob) in enumerate(dataloader):\n",
        "        x1 = img1.float().to(device)\n",
        "        x2 = img2.float().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        prob_t = prob.to(torch.long)\n",
        "        #prob_t = prob.type(torch.FloatTensor)\n",
        "        prob_var = prob_t.to(device)\n",
        "        #prob_var = prob.to(device)\n",
        "        #prob_var = prob_var.unsqueeze(dim=1)\n",
        "        #print(prob_var.size())\n",
        "        #print(prob_var)\n",
        "        \n",
        "        output = model(x1, x2)\n",
        "        #output = output.reshape(1, -1)\n",
        "        #output = output.squeeze()\n",
        "        #print(output.size())\n",
        "        #print(output)\n",
        "        \n",
        "        loss = loss_fn(output, prob_var)\n",
        "        all_loss.append(loss.item())\n",
        "        acc = accuracy(output, prob_var)\n",
        "        all_acc.append(acc) \n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "            \n",
        "        if idx % 14 == 0:\n",
        "            message1 = \"TRAIN Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n",
        "                                                              len(dataloader))\n",
        "            message2 = \"Loss: [{0:.4f}]; Accuracy: [{1}]\".format(loss.item(),\n",
        "                                                                acc)\n",
        "            print(message1, message2)\n",
        "    \n",
        "    return all_loss, all_acc\n",
        "\n",
        "def val(model, loss_fn, dataloader, epoch, device):\n",
        "    model = model.to(device)\n",
        "    all_loss = []\n",
        "    all_acc =[]\n",
        "    \n",
        "    for idx, (img1, img2, prob) in enumerate(dataloader):\n",
        "        x1 = img1.float().to(device)\n",
        "        x2 = img2.float().to(device)\n",
        "        \n",
        "        prob_t = prob.to(torch.long)\n",
        "        #prob_t = prob.type(torch.FloatTensor)\n",
        "        prob_var = prob_t.to(device)\n",
        "        # prob_var = prob.to(device)\n",
        "        #prob_var = prob_var.unsqueeze(dim=1)\n",
        "        #print(prob_var.size())\n",
        "        #print(prob_var)\n",
        "        output = model(x1, x2)\n",
        "        #output = output.reshape(1, -1)\n",
        "        #output = output.squeeze()\n",
        "        #print(output.size())\n",
        "        #print(output)\n",
        "        loss = loss_fn(output, prob_var)\n",
        "        acc = accuracy(output, prob_var)\n",
        "        all_loss.append(loss.item())\n",
        "        all_acc.append(acc)\n",
        "                \n",
        "        #print_state(idx, epoch, len(dataloader), loss_fn.cls_loss, split=\"val\")\n",
        "        if idx % 14 == 0:\n",
        "            message1 = \"VAL Epoch [{0}]: [{1}/{2}] \".format(epoch, idx,\n",
        "                                                              len(dataloader))\n",
        "            message2 = \"Loss: [{0:.4f}]; Accuracy: [{1}]\".format(loss.item(), acc)\n",
        "            print(message1, message2)\n",
        "    return all_loss, all_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iZoeeWM9umb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = Args()\n",
        "data_aug = True\n",
        "train_transform=None\n",
        "if data_aug == False:\n",
        "  train_transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "else:\n",
        "  train_transform = transforms.Compose([transforms.Resize((224, 224)), \n",
        "                                        transforms.RandomHorizontalFlip(), \n",
        "                                        transforms.RandomRotation(20, resample=PIL.Image.BILINEAR), \n",
        "                                        transforms.ToTensor()])\n",
        "\n",
        "img_transforms = train_transform\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGzZEm6j94ML",
        "colab_type": "code",
        "outputId": "8740116a-a358-4c73-bc08-3f9981fcc8c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_loader = get_dataloader(args.split_traindata, args,\n",
        "                              img_transforms=img_transforms)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset loaded\n",
            "8400 samples in the train dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKQgt_NDrA5L",
        "colab_type": "code",
        "outputId": "743d4818-0a30-4840-ec19-deb95b1e235c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "val_loader = get_dataloader(args.split_valdata, args,\n",
        "                            img_transforms=img_transforms, split=\"val\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset loaded\n",
            "2800 samples in the val dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXQ2coX6-Z_0",
        "colab_type": "code",
        "outputId": "0dee2d71-6e47-4359-967b-f88c76b4e679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = RecognitionModel()\n",
        "loss_fn = RecognitionCriterion()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 553507836/553507836 [00:24<00:00, 22524260.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0rOSRuG-mci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# directory where we'll store model weights\n",
        "weights_dir = \"weights\"\n",
        "if not osp.exists(weights_dir):\n",
        "  \n",
        "    os.mkdir(weights_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJU0i3PpLAHm",
        "colab_type": "code",
        "outputId": "5da918b8-21ac-4548-cb88-07676632acd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8NbSOen-wOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check for CUDA\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRW8oa-H-3gT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=args.lr,\n",
        "                      momentum=args.momentum, weight_decay=args.weight_decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAS5FOei-8T1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if args.resume:\n",
        "#    checkpoint = torch.load(args.resume)\n",
        "#    model.load_state_dict(checkpoint['model'])\n",
        "#    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "#    # Set the start epoch if it has not been\n",
        "#    if not args.start_epoch:\n",
        "#        args.start_epoch = checkpoint['epoch']\n",
        "#\n",
        "#def save_checkpoint(state, filename=\"checkpoint.pth\", save_path=\"weights\"):\n",
        "#    # check if the save directory exists\n",
        "#    if not Path(save_path).exists():\n",
        "#        Path(save_path).mkdir()\n",
        "#\n",
        "#    save_path = Path(save_path, filename)\n",
        "#    torch.save(state, str(save_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCo_88qumGSj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ac5aa57-fd73-478d-a06d-a5f6f5eb0b34"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_epoch.pth.tar  gdrive  sample_data  weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHwvDkqP6IM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23bde28d-5606-4d44-b2e1-4d614fd6f78f"
      },
      "source": [
        "print(args.epochs)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0ddySP2_DPR",
        "colab_type": "code",
        "outputId": "9961fa71-4dec-4851-c8f2-5ef26a66339e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "check_point_name = 'best_epoch.pth.tar'\n",
        "# train and evalute for `epochs`\n",
        "loss_epoch_train = []\n",
        "loss_epoch_val = []\n",
        "acc_epoch_train = []\n",
        "acc_epoch_val = []\n",
        "best_acc = 0\n",
        "for epoch in range(args.start_epoch, args.epochs):\n",
        "    # scheduler.step()\n",
        "    train_loss, train_acc = train(model, loss_fn, optimizer, train_loader, epoch, device=device)\n",
        "    \n",
        "    av_loss = np.mean(train_loss)\n",
        "    av_acc = np.mean(train_acc)\n",
        "    loss_epoch_train.append(av_loss)\n",
        "    acc_epoch_train.append(av_acc)\n",
        "    \n",
        "    #if (epoch + 1) % args.save_every == 0:\n",
        "    #   save_checkpoint({\n",
        "    #        'epoch': epoch + 1,\n",
        "    #        'batch_size': train_loader.batch_size,\n",
        "    #        'model': model.state_dict(),\n",
        "    #        'optimizer': optimizer.state_dict()\n",
        "    #     }, filename=\"checkpoint_{0}.pth\".format(epoch + 1),\n",
        "    #         save_path=weights_dir)\n",
        "    \n",
        "    val_loss, val_acc = val(model, loss_fn, val_loader, epoch, device=device)\n",
        "    best=max(val_acc)\n",
        "    if best > best_acc:\n",
        "        best_acc = best\n",
        "        best_epoch=epoch\n",
        "        \n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'batch_size': train_loader.batch_size,\n",
        "            'model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "        \n",
        "        torch.save(checkpoint, check_point_name)\n",
        "        torch.save(loss_epoch_train, 'loss_epoch_train')\n",
        "        torch.save(loss_epoch_val,'loss_epoch_val')\n",
        "        torch.save(acc_epoch_train,'acc_epoch_train')\n",
        "        torch.save(acc_epoch_val,'acc_epoch_val')\n",
        "    \n",
        "    av_loss = np.mean(val_loss)\n",
        "    av_acc = np.mean(val_acc)\n",
        "    loss_epoch_val.append(av_loss)\n",
        "    acc_epoch_val.append(av_acc)\n",
        "    \n",
        "    \n",
        "print(\"Best Epoch: \",best_epoch, \"Best Acc: \", best_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN Epoch [0]: [0/525]  Loss: [0.6741]; Accuracy: [0.5]\n",
            "TRAIN Epoch [0]: [14/525]  Loss: [0.7416]; Accuracy: [0.375]\n",
            "TRAIN Epoch [0]: [28/525]  Loss: [0.6531]; Accuracy: [0.6875]\n",
            "TRAIN Epoch [0]: [42/525]  Loss: [0.6228]; Accuracy: [0.6875]\n",
            "TRAIN Epoch [0]: [56/525]  Loss: [0.6212]; Accuracy: [0.75]\n",
            "TRAIN Epoch [0]: [70/525]  Loss: [0.7024]; Accuracy: [0.5625]\n",
            "TRAIN Epoch [0]: [84/525]  Loss: [0.6403]; Accuracy: [0.75]\n",
            "TRAIN Epoch [0]: [98/525]  Loss: [0.7317]; Accuracy: [0.375]\n",
            "TRAIN Epoch [0]: [112/525]  Loss: [0.5835]; Accuracy: [0.6875]\n",
            "TRAIN Epoch [0]: [126/525]  Loss: [0.6725]; Accuracy: [0.5625]\n",
            "TRAIN Epoch [0]: [140/525]  Loss: [0.6553]; Accuracy: [0.625]\n",
            "TRAIN Epoch [0]: [154/525]  Loss: [0.6797]; Accuracy: [0.5625]\n",
            "TRAIN Epoch [0]: [168/525]  Loss: [0.6008]; Accuracy: [0.6875]\n",
            "TRAIN Epoch [0]: [182/525]  Loss: [0.7259]; Accuracy: [0.4375]\n",
            "TRAIN Epoch [0]: [196/525]  Loss: [0.6802]; Accuracy: [0.4375]\n",
            "TRAIN Epoch [0]: [210/525]  Loss: [0.7740]; Accuracy: [0.5625]\n",
            "TRAIN Epoch [0]: [224/525]  Loss: [0.6953]; Accuracy: [0.5625]\n",
            "TRAIN Epoch [0]: [238/525]  Loss: [0.6470]; Accuracy: [0.625]\n",
            "TRAIN Epoch [0]: [252/525]  Loss: [0.6097]; Accuracy: [0.875]\n",
            "TRAIN Epoch [0]: [266/525]  Loss: [0.6212]; Accuracy: [0.5625]\n",
            "TRAIN Epoch [0]: [280/525]  Loss: [0.6225]; Accuracy: [0.6875]\n",
            "TRAIN Epoch [0]: [294/525]  Loss: [0.5959]; Accuracy: [0.6875]\n",
            "TRAIN Epoch [0]: [308/525]  Loss: [0.5275]; Accuracy: [0.8125]\n",
            "TRAIN Epoch [0]: [322/525]  Loss: [0.6418]; Accuracy: [0.5625]\n",
            "TRAIN Epoch [0]: [336/525]  Loss: [0.5600]; Accuracy: [0.8125]\n",
            "TRAIN Epoch [0]: [350/525]  Loss: [0.7265]; Accuracy: [0.4375]\n",
            "TRAIN Epoch [0]: [364/525]  Loss: [0.6171]; Accuracy: [0.6875]\n",
            "TRAIN Epoch [0]: [378/525]  Loss: [0.6288]; Accuracy: [0.625]\n",
            "TRAIN Epoch [0]: [392/525]  Loss: [0.5862]; Accuracy: [0.6875]\n",
            "TRAIN Epoch [0]: [406/525]  Loss: [0.6949]; Accuracy: [0.625]\n",
            "TRAIN Epoch [0]: [420/525]  Loss: [0.6745]; Accuracy: [0.4375]\n",
            "TRAIN Epoch [0]: [434/525]  Loss: [0.7357]; Accuracy: [0.5]\n",
            "TRAIN Epoch [0]: [448/525]  Loss: [0.5655]; Accuracy: [0.6875]\n",
            "TRAIN Epoch [0]: [462/525]  Loss: [0.7634]; Accuracy: [0.4375]\n",
            "TRAIN Epoch [0]: [476/525]  Loss: [0.7097]; Accuracy: [0.75]\n",
            "TRAIN Epoch [0]: [490/525]  Loss: [0.7130]; Accuracy: [0.5]\n",
            "TRAIN Epoch [0]: [504/525]  Loss: [0.7631]; Accuracy: [0.5]\n",
            "TRAIN Epoch [0]: [518/525]  Loss: [0.7163]; Accuracy: [0.5625]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aewz-ecTtxG8",
        "colab_type": "code",
        "outputId": "bf6d0c99-a9ce-4fc7-cfb9-5759e565a731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epochs = range(1, len(loss_epoch_train) + 1)\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, loss_epoch_train, 'b', label='Training loss')\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, loss_epoch_val, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.savefig('train_val_loss.png')\n",
        "plt.clf()\n",
        "plt.show()\n",
        "\n",
        "epochs = range(1, len(acc_epoch_train) + 1)\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, acc_epoch_train, 'b', label='Training accuracy')\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, acc_epoch_val, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "#plt.savefig('train_val_acc.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niFaSQkREtJIUIiKi9T/zaaoGpHX4fgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGt1wF0Duthz",
        "colab_type": "code",
        "outputId": "fdb2b838-6a94-4b64-e4ac-1a487ae8e208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmFESr8o0Yax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp  -r /content/weights ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FTS0oi4uuU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 777 gdrive Train_val_loss_acc.png"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}